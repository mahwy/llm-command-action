/*************************************************************************************************

Welcome to Baml! To use this generated code, please run one of the following:

$ npm install @boundaryml/baml
$ yarn add @boundaryml/baml
$ pnpm add @boundaryml/baml

*************************************************************************************************/

// This file was generated by BAML: please do not edit it. Instead, edit the
// BAML files and re-generate this code using: baml-cli generate
// You can install baml-cli with:
//  $ npm install @boundaryml/baml
//
/* eslint-disable */
// tslint:disable
// @ts-nocheck
// biome-ignore format: autogenerated code

const fileMap = {
  
  "clients.baml": "// Learn more about clients at https://docs.boundaryml.com/docs/snippets/clients/overview\n\nclient<llm> CustomGPT4o {\n  provider openai\n  options {\n    model \"gpt-4o\"\n    api_key env.OPENAI_API_KEY\n  }\n}\n\nclient<llm> CustomGPT4oMini {\n  provider openai\n  retry_policy Exponential\n  options {\n    model \"gpt-4o-mini\"\n    api_key env.OPENAI_API_KEY\n  }\n}\n\nclient<llm> CustomSonnet {\n  provider anthropic\n  options {\n    model \"claude-3-5-sonnet-20241022\"\n    api_key env.ANTHROPIC_API_KEY\n  }\n}\n\n\nclient<llm> CustomHaiku {\n  provider anthropic\n  retry_policy Constant\n  options {\n    model \"claude-3-haiku-20240307\"\n    api_key env.ANTHROPIC_API_KEY\n  }\n}\n\n// https://docs.boundaryml.com/docs/snippets/clients/round-robin\nclient<llm> CustomFast {\n  provider round-robin\n  options {\n    // This will alternate between the two clients\n    strategy [CustomGPT4oMini, CustomHaiku]\n  }\n}\n\n// https://docs.boundaryml.com/docs/snippets/clients/fallback\nclient<llm> OpenaiFallback {\n  provider fallback\n  options {\n    // This will try the clients in order until one succeeds\n    strategy [CustomGPT4oMini, CustomGPT4oMini]\n  }\n}\n\n// https://docs.boundaryml.com/docs/snippets/clients/retry\nretry_policy Constant {\n  max_retries 3\n  // Strategy is optional\n  strategy {\n    type constant_delay\n    delay_ms 200\n  }\n}\n\nretry_policy Exponential {\n  max_retries 2\n  // Strategy is optional\n  strategy {\n    type exponential_backoff\n    delay_ms 300\n    multiplier 1.5\n    max_delay_ms 10000\n  }\n}",
  "command.baml": "\nclass CommandOuputInPullRequest {\n  pull_request_comment string @description(#\"\n    A comment to add to the pull request as a response to the command.\n  \"#)\n  summary string @description(#\"\n    A summary of the input prompt and the output response.\n  \"#)\n}\n\nclass PullRequest {\n  title string\n  body string\n  comments Comment[]\n}\n\nclass Comment {\n  author string\n  body string\n}\n\nclass File {\n  name string?\n  path string\n  content string\n}\n\n\n\nfunction ExecuteCommandInPullRequest(inputPrompt: string, targetFiles: File[], pullRequest: PullRequest, referenceFiles: File[]) -> CommandOuputInPullRequest {\n  // Specify a client as provider/model-name\n  // you can use custom LLM params with a custom client name from clients.baml like \"client CustomHaiku\"\n  client \"openai/gpt-4o\" // Set OPENAI_API_KEY to use this client.\n  prompt #\"\n\n    {{ _.role(\"system\")}}\n    Execute a given prompt for given target files and a pull request and return the ouput response.\n\n    {{ _.role(\"user\")}}\n\n    {{ inputPrompt }}\n\n    <targetFiles>\n    {% for f in targetFiles %}\n    <file>\n    {{f.path}}\n    </file>\n    {% endfor %}\n    </targetFiles>\n\n    <pullRequest>\n    <title>\n    {{ pullRequest.title }}\n    </title>\n    <body>\n    {{ pullRequest.body }}\n    </body>\n    <comments>\n    {% for c in pullRequest.comments %}\n    <comment>\n    <author>\n    {{ c.author }}\n    </author>\n    <body>\n    {{ c.body }}\n    </body>\n    </comment>\n    {% endfor %}\n    </pullRequest>\n    \n    {{ ctx.output_format }}\n\n    <referenceFiles>\n    {% for f in referenceFiles %}\n    <file>\n    {% if f.name %}\n    <name>\n    {{f.name}}\n    </name>\n    {% endif %}\n    <path>\n    {{f.path}}\n    </path>\n    <content>\n    {{f.content}}\n    </content>\n    </file>\n    {% endfor %}\n    </referenceFiles>\n  \"#\n}\n\n\n\ntest sql_schema_review {\n  functions [ExecuteCommandInPullRequest]\n  args {\n    inputPrompt #\"\n      Review this SQL schema definition. Check for normalization, naming conventions, and indexing.\n      Suggest improvements or raise warnings if there are any anti-patterns.\n      Please write the response in markdown format in a concise manner.\n    \"#\n    targetFiles [\n      {\n        path \"schema.sql\"\n        content #\"\n          CREATE TABLE user (\n            id INT PRIMARY KEY,\n            name VARCHAR(255),\n            email VARCHAR(255)\n          );\n\n          CREATE TABLE post (\n            id INT PRIMARY KEY,\n            title VARCHAR(255),\n            content TEXT,\n            user_id INT,\n            FOREIGN KEY (user_id) REFERENCES user(id)\n          );\n\n          CREATE INDEX idx_posts_user_id ON post(user_id);\n        \"#\n      }\n    ]\n    pullRequest {\n      title \"Add indexes to improve performance\"\n      body \"We need to add indexes to improve the performance of the queries.\"\n      comments [\n        { author \"John Doe\", body \"Looks good to me.\" }\n      ]\n    }\n    referenceFiles [\n      {\n        path \"guidelines/db-schema-style.md\"\n        content #\"\n          # Database Schema Style Guidelines\n\n          ## Table Naming\n          - Use plural nouns for table names.\n          - Use lowercase with underscores for table names.\n          - Use descriptive names that reflect the data they contain.\n        \"#\n      }\n    ]\n  }\n}\n",
  "generators.baml": "// This helps use auto generate libraries you can use in the language of\n// your choice. You can have multiple generators if you use multiple languages.\n// Just ensure that the output_dir is different for each generator.\ngenerator target {\n    // Valid values: \"python/pydantic\", \"typescript\", \"ruby/sorbet\", \"rest/openapi\"\n    output_type \"typescript\"\n\n    // Where the generated code will be saved (relative to baml_src/)\n    output_dir \"../src\"\n\n    // The version of the BAML package you have installed (e.g. same version as your baml-py or @boundaryml/baml).\n    // The BAML VSCode extension version should also match this version.\n    version \"0.201.0\"\n\n    // Valid values: \"sync\", \"async\"\n    // This controls what `b.FunctionName()` will be (sync or async).\n    default_client_mode async\n}\n",
}
export const getBamlFiles = () => {
    return fileMap;
}